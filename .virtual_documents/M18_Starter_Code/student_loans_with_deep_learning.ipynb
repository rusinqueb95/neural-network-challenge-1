


# Imports
import pandas as pd
import tensorflow as tf
from tensorflow.keras.layers import Dense
from tensorflow.keras.models import Sequential
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from pathlib import Path








# Read the csv into a Pandas DataFrame
file_path = "https://static.bc-edx.com/ai/ail-v-1-0/m18/lms/datasets/student-loans.csv"
loans_df = pd.read_csv(file_path)

# Review the DataFrame
loans_df.head()


# Review the data types associated with the columns
loans_df.dtypes


# Check the credit_ranking value counts
loans_df["credit_ranking"].value_counts()





# Define the target set y using the credit_ranking column
y = loans_df["credit_ranking"]

# Display a sample of y
y[:5]



# Define features set X by selecting all columns but credit_ranking
X = loans_df.drop(columns=["credit_ranking"])


# Review the features DataFrame
X.head()






# Split the preprocessed data into a training and testing dataset
# Assign the function a random_state equal to 1
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)






# Create a StandardScaler instance
scaler = StandardScaler()


# Fit the scaler to the features training dataset
X_scaler = scaler.fit(X_train)


# Fit the scaler to the features training dataset
X_train_scaled = X_scaler.transform(X_train)
X_test_scaled = X_scaler.transform(X_test)








# Define the the number of inputs (features) to the model
number_inputs = 11


# Review the number of features
number_inputs



# Define the number of hidden nodes for the first hidden layer

hidden_nodes_layer1 = 5
# Define the number of hidden nodes for the second hidden layer
hidden_nodes_layer2 = 4

# Define the number of neurons in the output layer
number_output_neurons = 1



# Create the Sequential model instance
nn = tf.keras.models.Sequential()


# Add the first hidden layer
nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_inputs, activation="relu"))


# Add the second hidden layer
nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation="relu"))


# Add the output layer to the model specifying the number of output neurons and activation function
nn.add(tf.keras.layers.Dense(units=number_output_neurons, activation="sigmoid"))



# Display the Sequential model summary
nn.summary()






# Compile the Sequential model
nn.compile(loss="binary_crossentropy", optimizer="adam", metrics=["accuracy"])



# Fit the model using 50 epochs and the training data
fit_model = nn.fit(X_train_scaled, y_train, epochs=50)






# Evaluate the model loss and accuracy metrics using the evaluate method and the test data

model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)

# Display the model loss and accuracy results
print(f"Loss: {model_loss}, Accuracy: {model_accuracy}")






# Set the model's file path
file_path = Path("student_loans.keras")


# Export your model to a keras file
nn.save(file_path)









# Set the model's file path
file_path = Path("student_loans.keras")


# Load the model to a new object
nn_imported = tf.keras.models.load_model(file_path)






# Make predictions with the test data
predictions = nn_imported.predict(X_test_scaled)


# Display a sample of the predictions
predictions[:5]



# Save the predictions to a DataFrame and round the predictions to binary results
predictions_df = pd.DataFrame(predictions, columns=["predictions"]).round(0)






# Print the classification report with the y test data and predictions
print(classification_report(y_test, predictions_df))




























